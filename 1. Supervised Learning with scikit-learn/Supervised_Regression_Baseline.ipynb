{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "f90f25c9-acc8-4c12-a8c7-95ad087e3257",
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Load the dataset\ndf = pd.read_csv('your_data.csv')\n\n# Display dataset info\nprint(f\"Dataset Shape: {df.shape}\")\nprint(f\"First 5 Rows:\\n{df.head()}\")\n\n# Separate features and target\nX = df.drop(columns=['target_column'], axis=1)\ny = df['target_column']\n\n# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Identify numeric and categorical features\nnumeric_features = X.select_dtypes(include=[np.number]).columns\ncategorical_features = X.select_dtypes(include=[np.object_]).columns\n\n# Preprocessing pipelines\nnum_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))\n])\n\n# Combine preprocessors into a column transformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_transformer, numeric_features),\n        ('cat', cat_transformer, categorical_features)\n    ]\n)\n\n# Define models for comparison\nmodels = {\n    'LinearRegression': Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', LinearRegression())\n    ]),\n    'RidgeRegression': Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', Ridge())\n    ]),\n    'LassoRegression': Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', Lasso())\n    ]),\n    'RandomForestRegressor': Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', RandomForestRegressor(random_state=42))\n    ]),\n    'DecisionTreeRegressor': Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', DecisionTreeRegressor(random_state=42))\n    ])\n}\n\n# Cross-validation and model evaluation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nmodel_scores = {}\n\nprint(\"\\nEvaluating models using cross-validation...\\n\")\nfor model_name, model_pipeline in models.items():\n    cv_scores = -1 * cross_val_score(model_pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n    model_scores[model_name] = np.mean(cv_scores)\n    rmse_scores = np.sqrt(-cv_scores)  # Convert negative MSE to RMSE\n    print(f\"{model_name}:\")\n    print(f\"  Mean RMSE: {np.mean(rmse_scores):.4f}\")\n    print(f\"  Standard Deviation RMSE: {np.std(rmse_scores):.4f}\")\n    print(f\"  95% Confidence Interval RMSE: {np.quantile(rmse_scores, [0.025, 0.975])}\")\n\n# Select the best model based on CV scores\nbest_model_name = min(model_scores, key=model_scores.get)\nprint(f\"\\nBest model based on cross-validation scores: {best_model_name}\")\n\n# Plot boxplot for cross-validation results\nplt.figure(figsize=(10, 6))\nplt.boxplot([np.sqrt(-1 * cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1))\n             for pipeline in models.values()],\n            labels=models.keys())\nplt.title('Model Performance - Cross-Validation (RMSE)')\nplt.ylabel('Root Mean Squared Error (RMSE)')\nplt.show()\n\n# Hyperparameter tuning\nparam_grid = {\n    'LinearRegression': {},\n    'RidgeRegression': {'model__alpha': [0.1, 1.0, 10.0]},\n    'LassoRegression': {'model__alpha': [0.1, 1.0, 10.0]},\n    'RandomForestRegressor': {\n        'model__n_estimators': [50, 100, 200],\n        'model__max_depth': [None, 10, 20],\n        'model__min_samples_split': [2, 5]\n    },\n    'DecisionTreeRegressor': {\n        'model__max_depth': [None, 10, 20],\n        'model__min_samples_split': [2, 5]\n    }\n}\n\nif best_model_name in param_grid:\n    print(f\"\\nPerforming grid search for {best_model_name}...\")\n    grid_search = GridSearchCV(\n        models[best_model_name],\n        param_grid[best_model_name],\n        cv=kf,\n        scoring='neg_mean_squared_error',\n        n_jobs=-1,\n        verbose=2\n    )\n    grid_search.fit(X_train, y_train)\n\n    print(f\"\\nBest parameters for {best_model_name}: {grid_search.best_params_}\")\n    print(f\"Best cross-validated RMSE: {np.sqrt(-grid_search.best_score_):.4f}\")\n\n    # Evaluate the best model on the test set\n    final_model = grid_search.best_estimator_\n    y_pred = final_model.predict(X_test)\n\n    # Calculate all metrics\n    mse = mean_squared_error(y_test, y_pred)\n    rmse = np.sqrt(mse)\n    mae = mean_absolute_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n\n    # Display metrics\n    print(f\"\\nTest Set Metrics for {best_model_name}:\")\n    print(f\"  Mean Squared Error (MSE): {mse:.4f}\")\n    print(f\"  Root Mean Squared Error (RMSE): {rmse:.4f}\")\n    print(f\"  Mean Absolute Error (MAE): {mae:.4f}\")\n    print(f\"  R2 Score: {r2:.4f}\")\nelse:\n    print(\"No hyperparameters to tune for the selected model.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}